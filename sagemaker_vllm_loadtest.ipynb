{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81789fd9-0534-4247-a361-14b6d7b8e501",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mistral 7B deployment guide\n",
    "\n",
    "Following this tutorial from DJL sample code, you will use LMI container from DLC to SageMaker and run inference with it.\n",
    "\n",
    "\n",
    "https://docs.djl.ai/docs/demos/aws/sagemaker/large-model-inference/sample-llm/vllm_deploy_mistral_7b.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfeff6d4-fa0d-45b5-b313-ec1c83ba90ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sagemaker --upgrade  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f7b9497-1144-4f30-89e2-45e303b7ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb300692-67c1-4fb9-a07d-f6b3eeb8ba15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.model_id=mistralai/Mistral-7B-v0.1\n",
    "option.dtype=fp16\n",
    "option.task=text-generation\n",
    "option.rolling_batch=vllm\n",
    "option.tensor_parallel_degree=1\n",
    "option.device_map=auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d1f827e-b508-4a19-a728-72651abc756b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mymodel/\n",
      "mymodel/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir mymodel\n",
    "mv serving.properties mymodel/\n",
    "tar czvf mymodel.tar.gz mymodel/\n",
    "rm -rf mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c2b844a-b70e-40cb-b907-294cc2d56b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- &gt; s3://sagemaker-us-east-1-70768********/large-model-lmi/code/mymodel.tar.gz\n"
     ]
    }
   ],
   "source": [
    "image_uri = image_uris.retrieve(\n",
    "        framework=\"djl-deepspeed\",\n",
    "        region=sess.boto_session.region_name,\n",
    "        version=\"0.25.0\"\n",
    "    )\n",
    "\n",
    "s3_code_prefix = \"large-model-lmi/code\"\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "code_artifact = sess.upload_data(\"mymodel.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- &gt; {code_artifact}\")\n",
    "\n",
    "model = Model(image_uri=image_uri, model_data=code_artifact, role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bfe32e6-e3d8-47c3-b083-95557c43f18f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.25.0-deepspeed0.11.0-cu118'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f41d8-9e8e-480a-a4f6-e7ab024df623",
   "metadata": {},
   "source": [
    "The deployment will take several minutes. Once finished, we can invoke the model with python sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8afc0483-95c8-4311-9395-1c5e474ea973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "instance_type = \"ml.g5.2xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"lmi-model\")\n",
    "\n",
    "model.deploy(initial_instance_count=1,\n",
    "             instance_type=instance_type,\n",
    "             endpoint_name=endpoint_name\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc3f78f-17e7-4936-8556-7cd19b662a79",
   "metadata": {},
   "source": [
    "If you have already the endpoint deployed, you can just copy the endpoint name to do the load test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c6a4e57-f949-42c3-8a69-5adb89abf03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmi-model-2024-02-27-03-02-59-220\n"
     ]
    }
   ],
   "source": [
    "endpoint_name\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79b68280-d696-4ad7-9e8c-8af0ed22b07b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Create a Boto3 client for SageMaker Runtime\n",
    "sagemaker_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "max_tokens_to_sample = 200\n",
    " \n",
    "# Define the prompt and other parameters\n",
    "prompt = f\"\"\"\n",
    "Write a long and high-quality story about two dogs. Make the story longer than {max_tokens_to_sample}\n",
    "\n",
    "Rex and Charlie were best friends who did everything together. They lived next door to each other with their human families and spent all day playing in the backyard. Rex was a golden retriever, always happy and eager for fun. Charlie was a German shepherd, more serious but very loyal. \n",
    "\n",
    "Every morning, Rex and Charlie would wake up and bark excitedly, ready to start the day's adventures. Their families would let them out into the backyard and they'd run around chasing each other and sniffing for interesting smells. After tiring themselves out, they'd nap in the shade of the big oak tree, Rex's tail still thumping contentedly even in his sleep. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# hyperparameters for llm\n",
    "parameters = {\n",
    "    \"max_new_tokens\": max_tokens_to_sample,\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.8,\n",
    "}\n",
    "\n",
    "contentType = 'application/json'\n",
    "\n",
    "body = json.dumps({\n",
    "    \"inputs\": prompt,\n",
    "    # specify the parameters as needed\n",
    "    \"parameters\": parameters\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f6965cd-fd24-4cff-bf22-6daffb2fb47b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = sagemaker_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, Body=body, ContentType=contentType)\n",
    "\n",
    "# Process the response\n",
    "response_body = json.loads(response.get('Body').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "123968e9-564c-4037-b73c-472ee6face1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the afternoon, Rex and Charlie would go for a walk with their humans. They'd stroll down the street, stopping to greet other dogs and people along the way. Sometimes they'd stop for a treat at the local pet store, where they knew the owner and got lots of attention. \n",
      "\n",
      "At night, Rex and Charlie would snuggle up together on their favorite couch, watching their humans watch TV. They'd listen to the show and nudge each other when something funny happened. When their humans finally went to bed, Rex and Charlie would stay up a little longer, playing with their favorite toys or just snuggling together. \n",
      "\n",
      "Rex and Charlie's friendship was a joy to their families, who loved seeing them play and explore together. But more than that, their friendship was a joy to Rex and Charlie themselves. They were always there for each other, through good times and bad, and they always knew they\n"
     ]
    }
   ],
   "source": [
    "print(response_body['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eddaf2-b47a-4500-baac-d1d2c475950c",
   "metadata": {},
   "source": [
    "### Testing the throughput and lantency with locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "704feb8e-425f-4fdc-b1d3-cea8faa7d21a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: locust in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.23.1)\n",
      "Requirement already satisfied: gevent>=22.10.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (23.9.0.post1)\n",
      "Requirement already satisfied: flask>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (3.0.0)\n",
      "Requirement already satisfied: Werkzeug>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (3.0.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (2.31.0)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (1.0.6)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (25.1.1)\n",
      "Requirement already satisfied: geventhttpclient>=2.0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (2.0.11)\n",
      "Requirement already satisfied: ConfigArgParse>=1.5.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (1.7)\n",
      "Requirement already satisfied: psutil>=5.9.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (5.9.5)\n",
      "Requirement already satisfied: Flask-Login>=0.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (0.6.3)\n",
      "Requirement already satisfied: Flask-Cors>=3.0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (4.0.0)\n",
      "Requirement already satisfied: roundrobin>=0.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (0.0.4)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from flask>=2.0.0->locust) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from flask>=2.0.0->locust) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from flask>=2.0.0->locust) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from flask>=2.0.0->locust) (1.6.3)\n",
      "Requirement already satisfied: zope.event in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gevent>=22.10.2->locust) (5.0)\n",
      "Requirement already satisfied: zope.interface in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gevent>=22.10.2->locust) (6.1)\n",
      "Requirement already satisfied: greenlet>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gevent>=22.10.2->locust) (3.0.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from geventhttpclient>=2.0.11->locust) (2023.7.22)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from geventhttpclient>=2.0.11->locust) (1.16.0)\n",
      "Requirement already satisfied: brotli in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from geventhttpclient>=2.0.11->locust) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->locust) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->locust) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->locust) (1.26.18)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Werkzeug>=2.0.0->locust) (2.1.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from zope.event->gevent>=22.10.2->locust) (68.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0fe53dfd-0d46-4cf4-8db5-d27f0fe4688a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting locustfile.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile locustfile.py\n",
    "\n",
    "from locust import User, task, between\n",
    "import logging\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Create a Boto3 client for SageMaker Runtime\n",
    "sagemaker_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "endpoint_name = \"lmi-model-2024-02-27-03-02-59-220\"\n",
    "max_tokens_to_sample = 200\n",
    "\n",
    "# Define the prompt and other parameters\n",
    "prompt = f\"\"\"\n",
    "Write a long and high-quality story about two dogs. Make the story longer than {max_tokens_to_sample}\n",
    "\n",
    "Rex and Charlie were best friends who did everything together. They lived next door to each other with their human families and spent all day playing in the backyard. Rex was a golden retriever, always happy and eager for fun. Charlie was a German shepherd, more serious but very loyal. \n",
    "\n",
    "Every morning, Rex and Charlie would wake up and bark excitedly, ready to start the day's adventures. Their families would let them out into the backyard and they'd run around chasing each other and sniffing for interesting smells. After tiring themselves out, they'd nap in the shade of the big oak tree, Rex's tail still thumping contentedly even in his sleep. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# hyperparameters for llm\n",
    "parameters = {\n",
    "    \"max_new_tokens\": max_tokens_to_sample,\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.8,\n",
    "}\n",
    "\n",
    "contentType = 'application/json'\n",
    "\n",
    "body = json.dumps({\n",
    "    \"inputs\": prompt,\n",
    "    # specify the parameters as needed\n",
    "    \"parameters\": parameters\n",
    "})\n",
    "\n",
    "\n",
    "class LLMUser(User):\n",
    "    @task\n",
    "    def generation(self):\n",
    "        # Invoke the model\n",
    "        with self.environment.events.request.measure(\"[Send]\", \"Prompt\"):\n",
    "            response = sagemaker_client.invoke_endpoint(\n",
    "                            EndpointName=endpoint_name, Body=body, ContentType=contentType)\n",
    "            # Process the response\n",
    "            response_body = json.loads(response.get('Body').read())\n",
    "            logging.info(response_body['generated_text'])\n",
    "            \n",
    "        logging.info(\"Finished generation!\")            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c3639-c076-445c-9935-a7c076b5d26f",
   "metadata": {},
   "source": [
    "The configuration with Command Line Options https://docs.locust.io/en/stable/configuration.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c0300-38af-44da-9657-266eaf8f1775",
   "metadata": {
    "tags": []
   },
   "source": [
    "--users <int> Peak number of concurrent Locust users. Primarily used together with --headless or --autostart.\n",
    "    \n",
    "--headless Disable the web interface, and start the test immediately.\n",
    "    \n",
    "--csv Store request stats to files in CSV format.\n",
    "\n",
    "--spawn-rate <float> Rate to spawn users at (users per second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b92b060-de61-4d6f-a63f-8225449ba41f",
   "metadata": {},
   "source": [
    "In this example, the --users option sets the total number of users to 30, and the --spawn-rate option sets the rate of user spawning to 30 users per second. By using the same value for --spawn-rate as the total number of users, all 30 users will be spawned immediately. Therefore, at any given time during the test, there will be a maximum of 30 concurrent users.\n",
    "\n",
    "Please note that the --run-time option sets the duration of the test in seconds. In this example, the test will run for 120 seconds before stopping.\n",
    "\n",
    "!locust --headless --users 10 --spawn-rate 10 --run-time 120 --csv ./benchmark_metric/benchmark_u30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa215728-03ec-4a37-85b8-2d7a625eeb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-27 03:47:43,428] ip-172-16-188-233.ec2.internal/INFO/locust.main: Run time limit set to 120 seconds\n",
      "[2024-02-27 03:47:43,428] ip-172-16-188-233.ec2.internal/INFO/locust.main: Starting Locust 2.23.1\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
      "\n",
      "[2024-02-27 03:47:43,429] ip-172-16-188-233.ec2.internal/INFO/locust.runners: Ramping to 30 users at a rate of 30.00 per second\n",
      "[2024-02-27 03:47:43,430] ip-172-16-188-233.ec2.internal/INFO/locust.runners: All users spawned: {\"LLMUser\": 30} (30 total users)\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
      "\n",
      "[2024-02-27 03:47:53,106] ip-172-16-188-233.ec2.internal/INFO/root: In the afternoon, the two dogs would go on long walks with their families, exploring the neighborhood and saying hello to all their friends. They'd stop at the park and play fetch with a ball or Frisbee, sometimes stopping to roll around in the grass. Rex would often chase after squirrels or birds, but Charlie would always be there to stop him before he got too far. \n",
      "\n",
      "At night, the two dogs would curl up together on the couch, their heads resting on each other's bellies. Their families would watch TV or read books while the dogs dozed off, content in each other's company. \n",
      "\n",
      "Rex and Charlie were the best of friends, always there for each other and always having fun. They lived a simple, but happy life together, and their families were grateful for their companionship.\n",
      "[2024-02-27 03:47:53,107] ip-172-16-188-233.ec2.internal/INFO/root: Finished generation!\n",
      "[2024-02-27 03:47:53,152] ip-172-16-188-233.ec2.internal/INFO/root: Later in the day, when their humans were home from work, Rex and Charlie would get a treat and then go on a walk around the neighborhood. They loved exploring new smells and meeting new people and dogs, and always came back home with a pawful of grass stuck to their fur. \n",
      "\n",
      "In the evening, Rex and Charlie would curl up on the couch with their humans and watch TV together. They'd snuggle up close and fall asleep, dreaming of all the fun they'd had that day and looking forward to tomorrow.\n",
      "\n",
      "Rex and Charlie's friendship was a bond that would last forever. They were always there for each other, through the good times and the bad. Their families knew they were lucky to have such wonderful dogs in their lives, and they cherished the time they got to spend with them.\n",
      "[2024-02-27 03:47:53,152] ip-172-16-188-233.ec2.internal/INFO/root: Finished generation!\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "[Send]   Prompt       2     0(0.00%) |   9695    9668    9722   9700 |    0.00        0.00\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       2     0(0.00%) |   9695    9668    9722   9700 |    0.00        0.00\n",
      "\n",
      "[2024-02-27 03:47:54,226] ip-172-16-188-233.ec2.internal/INFO/root: One day, Rex and Charlie's human families decided to go on vacation. They packed their bags and headed off, leaving the two dogs behind. Rex and Charlie were heartbroken and spent the whole day moping around the house, whining and searching for their owners. \n",
      "\n",
      "The next morning, Rex and Charlie woke up to find that their humans were still gone. They looked out the window and saw that their families had left the backyard gate open. \n",
      "\n",
      "\"Let's go on an adventure!\" said Rex excitedly.\n",
      "\n",
      "\"I'm not sure about that,\" said Charlie, \"our owners are gone and we don't know what might happen if we leave the house.\"\n",
      "\n",
      "\"But it's been so long since we've had an adventure,\" said Rex, \"let's just go for a little while and see what happens.\"\n",
      "\n",
      "Charlie was hesitant, but he couldn\n",
      "[2024-02-27 03:47:54,226] ip-172-16-188-233.ec2.internal/INFO/root: Finished generation!\n",
      "[2024-02-27 03:47:54,231] ip-172-16-188-233.ec2.internal/INFO/root: Later in the day, Rex and Charlie would go for walks with their families. Rex would bound ahead, his tongue hanging out, while Charlie trotted along behind, taking in all the sights and smells. They'd stop to say hello to other dogs and humans they met along the way, and Rex would always manage to get his paws on a few tasty treats. \n",
      "\n",
      "When it was time for dinner, Rex and Charlie would eagerly follow their families inside and sit patiently while their bowls were filled. They'd gobble up their food and then lie down next to each other, bellies full and satisfied. \n",
      "\n",
      "At the end of the day, Rex and Charlie would curl up together on the floor and fall asleep, content and exhausted from all their adventures. They'd dream of more fun and excitement to come, and wake up the next morning ready to start all over again. \n",
      "\n",
      "\n",
      "[2024-02-27 03:47:54,231] ip-172-16-188-233.ec2.internal/INFO/root: Finished generation!\n",
      "[2024-02-27 03:47:54,233] ip-172-16-188-233.ec2.internal/INFO/root: In the afternoon, their human families would come home from work and play with them for a while. Rex would fetch his favorite ball, while Charlie preferred to chase sticks. Their humans would take them for a walk around the neighborhood, where they'd meet other dogs and people, who always stopped to pet them. \n",
      "\n",
      "In the evenings, Rex and Charlie would sit together on the porch, watching the sun set. They'd listen to the crickets chirping and the owls hooting, feeling the cool breeze on their fur. When their humans came home, they'd get excited and wag their tails, waiting for dinner and more playtime. \n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "[Send]   Prompt     362     0(0.00%) |   9947    1056   10830  10000 |    3.02        0.00\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated     362     0(0.00%) |   9947    1056   10830  10000 |    3.02        0.00\n",
      "\n",
      "Response time percentiles (approximated)\n",
      "Type     Name      50%    66%    75%    80%    90%    95%    98%    99%  99.9% 99.99%   100% # reqs\n",
      "--------||--------|------|------|------|------|------|------|------|------|------|------|------\n",
      "[Send]   Prompt    10000  10000  10000  10000  11000  11000  11000  11000  11000  11000  11000    362\n",
      "--------||--------|------|------|------|------|------|------|------|------|------|------|------\n",
      "         Aggregated    10000  10000  10000  10000  11000  11000  11000  11000  11000  11000  11000    362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!locust --headless --users 30 --spawn-rate 30 --run-time 120 --csv ./benchmark_metric/benchmark_u30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be37908-7c39-4756-bf28-0140d5ffa201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c7338-1358-4759-8577-fa26b14cad32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
