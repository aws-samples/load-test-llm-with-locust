{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bebddc7-6b31-429f-816c-66e63bef5fe1",
   "metadata": {},
   "source": [
    "### Import a customized model into Amazon Bedrock\n",
    "\n",
    "You can create a custom model in Amazon Bedrock by using the Amazon Bedrock Custom Model Import feature to import Foundation Models that you have customized in other environments, such as Amazon SageMaker AI. For example, you might have a model that you have created in Amazon SageMaker AI that has proprietary model weights. You can now import that model into Amazon Bedrock and then leverage Amazon Bedrock features to make inference calls to the model.\n",
    "\n",
    "You can use a model that you import with on demand throughput. Use the InvokeModel or InvokeModelWithResponseStream operations to make inference calls to the model. For more information, see Submit a single prompt with InvokeModel.\n",
    "\n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae93938a-3890-43e4-8428-909dc30e1852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import boto3\n",
    "from botocore.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2bd952c-690b-4235-9c18-b44a641f5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Bedrock Runtime client\n",
    "session = boto3.Session()\n",
    "client = session.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    config=Config(\n",
    "        connect_timeout=300,  # 5 minutes\n",
    "        read_timeout=300,     # 5 minutes\n",
    "        retries={'max_attempts': 3}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4f1ccc0-73a1-45de-b6cd-d98b79fb5271",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"arn:aws:bedrock:us-west-2:707684582322:imported-model/4mxlk57hcdv7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "964b0c6e-c917-47e1-a820-6a6d989d53f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_chat_template(messages):\n",
    "    prompt = \"\"\n",
    "    # First message is always user\n",
    "    prompt = \"<｜begin▁of▁sentence｜><｜User｜>\" + messages[0][\"content\"] + \"<｜Assistant｜>\"            \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93ff7a2b-3e30-4bd1-a21b-036c6a7651fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completion(messages, temperature=0.6, max_tokens=1024, top_p=0.9, model_id=model_id, max_retries=3):\n",
    "    \"\"\"\n",
    "    Simplified chat completion with retry mechanism\n",
    "    \n",
    "    Parameters:\n",
    "        messages (list): List of message dicts with 'role' and 'content'\n",
    "        temperature (float): Controls randomness (0.0-1.0)\n",
    "        max_tokens (int): Max tokens to generate\n",
    "        top_p (float): Nucleus sampling parameter\n",
    "        model_id (str): Model identifier\n",
    "        max_retries (int): Max retry attempts\n",
    "    \n",
    "    Returns:\n",
    "        dict: Model response with generated text\n",
    "    \"\"\"\n",
    "    prompt = apply_chat_template(messages)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.invoke_model(\n",
    "                modelId=model_id,\n",
    "                body=json.dumps({\n",
    "                    'prompt': prompt,\n",
    "                    'temperature': temperature,\n",
    "                    'max_gen_len': max_tokens,\n",
    "                    'top_p': top_p\n",
    "                }),\n",
    "                accept='application/json',\n",
    "                contentType='application/json'\n",
    "            )\n",
    "            result = json.loads(response['body'].read().decode('utf-8'))\n",
    "            #print(result)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(30)\n",
    "\n",
    "    raise Exception(\"Max retries reached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8da3b14d-7678-48bf-baea-84cf2b6ddd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conversation\n",
    "messages = [\n",
    "\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"\"\"please help me to generate python code:  \n",
    "        Given two sorted arrays nums1 and nums2 of size m and n respectively, return the median of the two sorted arrays.\n",
    "        The overall run time complexity should be O(log (m+n)).\"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c28b9402-415d-4c58-b754-ebc9889d5b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Case 1: Normal Conversation ===\n",
      "{'generation': '<think>\\nOkay, so I need to write a Python function that takes two sorted arrays, nums1 and nums2, of sizes m and n respectively, and returns their median. The catch is that the solution needs to have a time complexity of O(log(m + n)). Hmm, I remember that the median is the middle value of a sorted list, so if I can find the middle element between the two arrays efficiently, that would work.\\n\\nWait, both arrays are already sorted, right? That should help because I can probably use a two-pointer technique. Let me think about how that would work. So, I can start with two pointers, one at the beginning of each array, and another two at the end. Then, I compare the elements at these pointers and move the pointer with the smaller value forward. This way, I can find the median without having to sort the combined arrays, which would have been O(m + n log(m + n)) time.\\n\\nBut wait, how do I handle cases where m and n are odd or even? Let me think. The median is the middle element if the total number of elements is odd, but if it\\'s even, maybe the average of the two middle numbers. But in the problem statement, it just says \"the median,\" so I should check what\\'s expected. Oh, the problem doesn\\'t specify, but usually, in programming problems, the median is the lower of the two middle numbers when even, or the exact middle when odd. Hmm, but perhaps the problem expects the lower one? Or maybe it\\'s okay to return either, as long as it\\'s correct. Well, I\\'ll proceed with the approach that finds the middle element correctly.\\n\\nSo, the steps would be:\\n\\n1. Initialize two pointers, i for nums1 starting at 0, j for nums2 starting at 0.\\n2. Also, have pointers for the end of each array, like i_end for nums1 and j_end for nums2.\\n3. While i <= i_end and j <= j_end:\\n   a. Compare nums1[i] and nums2[j].\\n   b. If they are equal, that\\'s the median, so return it.\\n   c. If nums1[i] < nums2[j], move i forward.\\n   d. Else, move j forward.\\n4. After the loop, if one array is exhausted, the median is the last element of the other array.\\n\\nWait, but wait, this might not always give the correct median. Let me test this logic with some examples.\\n\\nSuppose nums1 = [1, 3, 5], nums2 = [2, 4]. The combined array would be [1,2,3,4,5], median is 3. Let\\'s see how the pointers move.\\n\\ni=0, j=0: nums1[i]=1 vs nums2[j]=2. 1<2, so i increments to 1.\\nNow, nums1[i]=3 vs nums2[j]=2. 3>2, so j increments to 1.\\nNow, nums1[i]=3 vs nums2[j]=4. 3<4, so i increments to 2 (i_end is 2 now). Now, since i > i_end, we exit the loop. The median is nums1[i-1] =3, which is correct.\\n\\nAnother example: nums1 = [1,2], nums2 = [3,4]. The combined is [1,2,3,4], median is (2+3)/2=2.5. But according to the code, after the loop, since i=2 and j=0, we take nums1\\'s last element, which is 2. Hmm, but the average of 2 and 3 is 2.5. So perhaps the code returns 2, which might not be correct if the problem expects an average. Wait, but maybe the problem expects the lower median. Or perhaps I need to adjust the code to handle even cases differently.\\n\\nWait, perhaps the code should return the average when the total number of elements is even. So I need to check if the total number of elements is even or odd. Let me think about that.\\n\\nTotal elements is m + n. If (m + n) is odd, return the middle element. If even, return the average of the two middle elements.\\n\\nSo, in the first example, m=3, n=2, total 5, which is odd. Median is 3. In the second example, total is 4, even. So the two middle elements are 2 and 3, average is 2.5.\\n\\nSo, in the code, after the loop, if i > i_end and j > j_end, then we\\'ve processed all elements. But wait, the loop condition is while i <= i_end and j <= j_end. So when one array is exhausted, we take the other\\'s last element, but that might not account', 'generation_token_count': 1024, 'stop_reason': 'length', 'prompt_token_count': 53}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Test Case 1: Normal Conversation ===\")\n",
    "response = chat_completion(messages)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f916281-c3e1-4a7d-a724-9e1c8ac4e1b6",
   "metadata": {},
   "source": [
    "### Testing the throughput and lantency with locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "785dd8e5-c1c3-4a26-b5e2-c011bd19d34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: locust in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.32.8)\n",
      "Requirement already satisfied: ConfigArgParse>=1.5.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (1.7)\n",
      "Requirement already satisfied: Flask-Cors>=3.0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (5.0.0)\n",
      "Requirement already satisfied: Flask-Login>=0.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (0.6.3)\n",
      "Requirement already satisfied: Werkzeug>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (3.1.3)\n",
      "Requirement already satisfied: flask>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (3.1.0)\n",
      "Requirement already satisfied: gevent>=22.10.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (24.11.1)\n",
      "Requirement already satisfied: geventhttpclient>=2.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (2.3.3)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (1.1.0)\n",
      "Requirement already satisfied: psutil>=5.9.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (6.1.1)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (26.2.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=70.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (75.8.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (2.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from locust) (4.12.2)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from flask>=2.0.0->locust) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from flask>=2.0.0->locust) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from flask>=2.0.0->locust) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from flask>=2.0.0->locust) (1.9.0)\n",
      "Requirement already satisfied: zope.event in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gevent>=22.10.2->locust) (5.0)\n",
      "Requirement already satisfied: zope.interface in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gevent>=22.10.2->locust) (7.2)\n",
      "Requirement already satisfied: greenlet>=3.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gevent>=22.10.2->locust) (3.1.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from geventhttpclient>=2.3.1->locust) (2024.12.14)\n",
      "Requirement already satisfied: brotli in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from geventhttpclient>=2.3.1->locust) (1.1.0)\n",
      "Requirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from geventhttpclient>=2.3.1->locust) (2.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->locust) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->locust) (3.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Werkzeug>=2.0.0->locust) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64199219-aa4a-45ea-b354-8b1aec5349ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting locustfile.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile locustfile.py\n",
    "\n",
    "from locust import User, task, between\n",
    "import logging\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "from botocore.config import Config\n",
    "\n",
    "# Initialize Bedrock Runtime client\n",
    "session = boto3.Session()\n",
    "client = session.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    config=Config(\n",
    "        connect_timeout=300,  # 5 minutes\n",
    "        read_timeout=300,     # 5 minutes\n",
    "        retries={'max_attempts': 3}\n",
    "    )\n",
    ")\n",
    "\n",
    "model_id = \"arn:aws:bedrock:us-west-2:707684582322:imported-model/4mxlk57hcdv7\"\n",
    "\n",
    "def apply_chat_template(messages):\n",
    "    prompt = \"\"\n",
    "    # First message is always user\n",
    "    prompt = \"<｜begin▁of▁sentence｜><｜User｜>\" + messages[0][\"content\"] + \"<｜Assistant｜>\"            \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def chat_completion(messages, temperature=0.6, max_tokens=1024, top_p=0.9, model_id=model_id, max_retries=3):\n",
    "    \"\"\"\n",
    "    Simplified chat completion with retry mechanism\n",
    "    \n",
    "    Parameters:\n",
    "        messages (list): List of message dicts with 'role' and 'content'\n",
    "        temperature (float): Controls randomness (0.0-1.0)\n",
    "        max_tokens (int): Max tokens to generate\n",
    "        top_p (float): Nucleus sampling parameter\n",
    "        model_id (str): Model identifier\n",
    "        max_retries (int): Max retry attempts\n",
    "    \n",
    "    Returns:\n",
    "        dict: Model response with generated text\n",
    "    \"\"\"\n",
    "    prompt = apply_chat_template(messages)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.invoke_model(\n",
    "                modelId=model_id,\n",
    "                body=json.dumps({\n",
    "                    'prompt': prompt,\n",
    "                    'temperature': temperature,\n",
    "                    'max_gen_len': max_tokens,\n",
    "                    'top_p': top_p\n",
    "                }),\n",
    "                accept='application/json',\n",
    "                contentType='application/json'\n",
    "            )\n",
    "            result = json.loads(response['body'].read().decode('utf-8'))\n",
    "            #print(result)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(30)\n",
    "\n",
    "    raise Exception(\"Max retries reached\")\n",
    "\n",
    "# Test conversation\n",
    "messages = [\n",
    "\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"\"\"please help me to generate python code:  \n",
    "        Given two sorted arrays nums1 and nums2 of size m and n respectively, return the median of the two sorted arrays.\n",
    "        The overall run time complexity should be O(log (m+n)).\"\"\"\n",
    "    }\n",
    "]\n",
    "    \n",
    "class LLMUser(User):\n",
    "    @task\n",
    "    def generation(self):\n",
    "        # Invoke the model\n",
    "        with self.environment.events.request.measure(\"[Send]\", \"Prompt\"):\n",
    "            response = chat_completion(messages)\n",
    "            logging.info(response.get('generation')[:100])\n",
    "            \n",
    "        logging.info(\"Finished generation!\")            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f7314-3d39-4c02-b9a3-362d25c7b838",
   "metadata": {},
   "source": [
    "The configuration with Command Line Options https://docs.locust.io/en/stable/configuration.html\n",
    "\n",
    "--users Peak number of concurrent Locust users. Primarily used together with --headless or --autostart.\n",
    "\n",
    "--headless Disable the web interface, and start the test immediately.\n",
    "\n",
    "--csv Store request stats to files in CSV format.\n",
    "\n",
    "--spawn-rate Rate to spawn users at (users per second)\n",
    "\n",
    "In this example, the --users option sets the total number of users to 30, and the --spawn-rate option sets the rate of user spawning to 30 users per second. By using the same value for --spawn-rate as the total number of users, all 30 users will be spawned immediately. Therefore, at any given time during the test, there will be a maximum of 30 concurrent users.\n",
    "\n",
    "Please note that the --run-time option sets the duration of the test in seconds. In this example, the test will run for 120 seconds before stopping.\n",
    "\n",
    "!locust --headless --users 30 --spawn-rate 30 --run-time 120 --csv ./benchmark_metric/benchmark_u30\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cba7ec-13f5-4712-b756-c9e42de43c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-07 08:05:26,981] ip-172-16-23-227/INFO/locust.main: Starting Locust 2.32.8\n",
      "[2025-02-07 08:05:26,981] ip-172-16-23-227/INFO/locust.main: Run time limit set to 60 seconds\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
      "\n",
      "[2025-02-07 08:05:26,982] ip-172-16-23-227/INFO/locust.runners: Ramping to 10 users at a rate of 10.00 per second\n",
      "[2025-02-07 08:05:26,983] ip-172-16-23-227/INFO/locust.runners: All users spawned: {\"LLMUser\": 10} (10 total users)\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
      "\n",
      "[2025-02-07 08:05:39,065] ip-172-16-23-227/INFO/root: <think>\n",
      "Okay, I need to find the median of two sorted arrays, nums1 and nums2, with sizes m and n re\n",
      "[2025-02-07 08:05:39,066] ip-172-16-23-227/INFO/root: Finished generation!\n",
      "[2025-02-07 08:05:39,067] ip-172-16-23-227/INFO/root: <think>\n",
      "Okay, I need to find the median of two sorted arrays. Hmm, both arrays are already sorted, w\n",
      "[2025-02-07 08:05:39,067] ip-172-16-23-227/INFO/root: Finished generation!\n",
      "[2025-02-07 08:05:39,067] ip-172-16-23-227/INFO/root: <think>\n",
      "Okay, so I need to write a Python function that finds the median of two sorted arrays, nums1\n",
      "[2025-02-07 08:05:39,068] ip-172-16-23-227/INFO/root: Finished generation!\n",
      "[2025-02-07 08:05:39,068] ip-172-16-23-227/INFO/root: <think>\n",
      "Okay, so I need to write a Python function to find the median of two sorted arrays. The prob\n",
      "[2025-02-07 08:05:39,068] ip-172-16-23-227/INFO/root: Finished generation!\n",
      "[2025-02-07 08:05:39,068] ip-172-16-23-227/INFO/root: <think>\n",
      "Okay, I need to find the median of two sorted arrays, nums1 and nums2, with sizes m and n re\n",
      "[2025-02-07 08:05:39,068] ip-172-16-23-227/INFO/root: Finished generation!\n",
      "[2025-02-07 08:05:39,069] ip-172-16-23-227/INFO/root: <think>\n",
      "Okay, I need to find the median of two sorted arrays, nums1 and nums2, where the sizes are m\n",
      "[2025-02-07 08:05:39,069] ip-172-16-23-227/INFO/root: Finished generation!\n",
      "[2025-02-07 08:05:39,069] ip-172-16-23-227/INFO/root: <think>\n",
      "Okay, I need to write a Python function that finds the median of two sorted arrays. The arra\n",
      "[2025-02-07 08:05:39,069] ip-172-16-23-227/INFO/root: Finished generation!\n",
      "[2025-02-07 08:05:39,070] ip-172-16-23-227/INFO/root: <think>\n",
      "Okay, so I need to write a Python function that takes two sorted arrays, nums1 and nums2, of\n",
      "[2025-02-07 08:05:39,070] ip-172-16-23-227/INFO/root: Finished generation!\n",
      "[2025-02-07 08:05:39,112] ip-172-16-23-227/INFO/root: <think>\n",
      "Okay, so I need to write a Python function that finds the median of two sorted arrays, nums1\n",
      "[2025-02-07 08:05:39,112] ip-172-16-23-227/INFO/root: Finished generation!\n",
      "[2025-02-07 08:05:40,369] ip-172-16-23-227/INFO/root: <think>\n",
      "Okay, I need to find the median of two sorted arrays, nums1 and nums2, with sizes m and n re\n",
      "[2025-02-07 08:05:40,369] ip-172-16-23-227/INFO/root: Finished generation!\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "[Send]   Prompt      10     0(0.00%) |  12214   12076   13381  12076 |    0.00        0.00\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated      10     0(0.00%) |  12214   12076   13381  12076 |    0.00        0.00\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "[Send]   Prompt      10     0(0.00%) |  12214   12076   13381  12076 |    0.00        0.00\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated      10     0(0.00%) |  12214   12076   13381  12076 |    0.00        0.00\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "[Send]   Prompt      10     0(0.00%) |  12214   12076   13381  12076 |    0.00        0.00\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated      10     0(0.00%) |  12214   12076   13381  12076 |    0.00        0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!locust --headless --users 10 --spawn-rate 10 --run-time 60 --csv ./benchmark_metric/benchmark_u10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe02f0-6b9d-4ac5-8829-24ad270c02ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
